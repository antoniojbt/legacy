{
 "metadata": {
  "name": "Ruffus-and-pipeline-building"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "05 04 2013\n",
      "Ruffus tutorial and pipeline construction using CGAT helper modules\n",
      "\n",
      "Ruffus documentation and tutorial are at:\n",
      "http://www.ruffus.org.uk/index.html\n",
      "\n",
      "Step 1 example:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from ruffus import *\n",
      "\n",
      "def first_task():\n",
      "    print \"Hello \"\n",
      "\n",
      "@follows(first_task)\n",
      "\n",
      "def second_task():\n",
      "    print \"world\"\n",
      "\n",
      "pipeline_run([second_task])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Hello \n",
        "world"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    Job completed\n",
        "Completed Task = first_task\n",
        "    Job completed\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Completed Task = second_task\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "General steps for pipeline building:\n",
      "\n",
      "Set-up:\n",
      "from the working directory run:\n",
      "\n",
      "(Is pipeline_quickstart.py self-contained or what do I need in order to run it?)\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "python <srcdir>pipeline_quickstart.py --name=test"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "This is part of the Pipeline module that contains many useful functions in order to construct a pipeline:\n",
      "Check: http://www.cgat.org/~andreas/documentation/cgat/BuildingPipelines.html\n",
      "\n",
      "Pipeline with a capital P is an Andreas convention to indicate helper modules for pipeline running. \n",
      "\n",
      "The CGAT code collection is at:\n",
      "http://www.cgat.org/~andreas/documentation/cgat/contents.html\n",
      "\n",
      "Quoting from above:\n",
      "Pipelines are implemented as a pipeline script in the source directory called pipeline_<somename>.py and a file pipeline_<somename>.ini with default configuration values.\n",
      "\n",
      "sphinxreport.ini and conf.py are used to generate automated reports\n",
      "\n",
      "<srcdir>pipeline_quickstart.py creates the directory structure and files with basic commands necessary to start building a pipeline with SphinxReport included.\n",
      "\n",
      "Paraphrasing:\n",
      "The pipelines will work from the input files present in the working directory and will create directories and locate outputs as indicated within the pipeline. Input files are identified by Ruffus by using their suffix (ie \"glob\".fastq.gz). Output files will be generated with the suffix and file/directory indicated in the pipeline.\n",
      "\n",
      "The Pipeline module automatically generates two directories used for exporting and publishing results:\n",
      "*./export/* This directory contains files that will be published by the pipeline or that are referred to by *./report/* . \n",
      "*./report/* This directory contains the automatically generated report.\n"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Once the directory is set-up start coding within pipeline_test.py:\n",
      "\n",
      "ie    ChIP-Exo pipeline example (pseudocode)\n",
      "\n",
      "check First-Notebook in /ifs/devel/antoniob/src/projects/ChIP-Exo"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from ruffus import *\n",
      "third_task_params = 'job0.input'\n",
      "@transform(third_task_params, suffix(\".input\"), \".output0\", \"some_extra.example\", 14)\n",
      "def third_task(input_file, out_file, extra_parameter_str, extra_parameter_num):\n",
      "    pass\n",
      "\n",
      "# check the input file is present:\n",
      "open('job0.input', \"w\")\n",
      "\n",
      "pipeline_run([third_task], verbose = 1)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    Job  = [job0.input -> job0.output0, some_extra.example, 14] completed\n",
        "Completed Task = third_task\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ls"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "First-notebook.ipynb                job0.input  \u001b[0m\u001b[01;34msrc\u001b[0m/\r\n",
        "Ruffus-and-pipeline-building.ipynb  \u001b[01;34mreport\u001b[0m/\r\n",
        "\u001b[m"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Running multiple jobs in one task:\n",
      "third_task_params = [\n",
      "                     'job1.input'\n",
      "                     'job2.input'\n",
      "                     'job3.input'\n",
      "                     ]\n",
      "\n",
      "# check input files are there:\n",
      "open('job1.input', \"w\")\n",
      "open('job2.input', \"w\")\n",
      "open('job3.input', \"w\")\n",
      "\n",
      "pipeline_run([third_task], verbose = 1)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  Task = third_task\n",
        "    Needing update:\n",
        "      Job  = [job0.input -> job0.output0, some_extra.example, 14]\n",
        "    fill_queue_with_job_parameters START\n",
        "   job_parameter_generator BEGIN\n",
        "   job_parameter_generator consider task = __main__.third_task\n",
        "   job_parameter_generator task __main__.third_task not in progress\n",
        "   job_parameter_generator start task __main__.third_task (parents completed)\n",
        "Task enters queue = third_task\n",
        "\n",
        "    Job  = [job0.input -> job0.output0, some_extra.example, 14] Missing file [job0.output0] \n",
        "   1 second PAUSE in job_parameter_generator\n",
        "\n",
        "\n",
        "\n",
        "    fill_queue_with_job_parameters=>('job0.input', 'job0.output0', 'some_extra.example', 14)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    incomplete tasks = __main__.third_task\n",
        "    fill_queue_with_job_parameters WAITING for task to complete\n",
        "    fill_queue_with_job_parameters END\n",
        "   Send param to Pooled Process START\n",
        "   Get next parameter size = 1\n",
        "   Get next parameter done\n",
        "   Send param to Pooled Process=>('job0.input', 'job0.output0', 'some_extra.example', 14)\n",
        "    Job  = [job0.input -> job0.output0, some_extra.example, 14] completed\n",
        "Completed Task = third_task\n",
        "    fill_queue_with_job_parameters START\n",
        "   job_parameter_generator END\n",
        "    fill_queue_with_job_parameters END\n",
        "   Get next parameter size = 1\n",
        "   Get next parameter done\n",
        "   Send param to Pooled Process END\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ls"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "First-notebook.ipynb                job0.input  job2.input  \u001b[0m\u001b[01;34mreport\u001b[0m/\r\n",
        "Ruffus-and-pipeline-building.ipynb  job1.input  job3.input  \u001b[01;34msrc\u001b[0m/\r\n",
        "\u001b[m"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Adding tasks to the recipe:\n",
      "\n",
      "# Additional task:\n",
      "\n",
      "@transform(third_task, suffix(\".output1\"), \".output2\")\n",
      "def fourth_task(input_file, output_file):\n",
      "    # make output file\n",
      "    open(output_file, \"w\")\n",
      "\n",
      "pipeline_run([fourth_task], verbose = 1)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    Job  = [job0.input -> job0.output0, some_extra.example, 14] completed\n",
        "Completed Task = third_task\n",
        "Uptodate Task = fourth_task\n",
        "\n",
        "\n",
        "WARNING:\n",
        "        'In Task def fourth_task(...):' No jobs were run because no files names matched. Please make sure that the regular expression is correctly specified. \n",
        "\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Ruffus tutorials 1 and 2:\n",
      "\n",
      "# Import Ruffus:\n",
      "\n",
      "from ruffus import *\n",
      "\n",
      "# Run first and second task, use of @follows:\n",
      "\n",
      "def first_task():\n",
      "    print \"Hello \"\n",
      "\n",
      "@follows(first_task)\n",
      "def second_task():\n",
      "    print \"world\"\n",
      "\n",
      "##pipeline_run([second_task])\n",
      "\n",
      "# Running multiple jobs in one task, use of @transform:\n",
      "\n",
      "# Establish task parameters to run:\n",
      "third_task_params = [\n",
      "                     'job1.input',\n",
      "                     'job2.input',\n",
      "                     'job3.input',\n",
      "                     ]\n",
      "\n",
      "# check input files are there:\n",
      "for input_file in third_task_params:\n",
      "    open(input_file, \"w\")\n",
      "\n",
      "# Recipe:\n",
      "\n",
      "@follows(second_task)\n",
      "@transform(third_task_params, suffix(\".input\"), \".output1\", \"some_extra.example\", 14)\n",
      "def third_task(input_file, output_file, extra_parameter_str, extra_parameter_num):\n",
      "    \n",
      "    # make output file\n",
      "    open(output_file, \"w\")\n",
      "    \n",
      "# check the input file is present:\n",
      "open('job1.input', \"w\")\n",
      "\n",
      "## pipeline_run([third_task], verbose = 1)\n",
      "\n",
      "# Adding tasks to the recipe:\n",
      "\n",
      "# Additional task:\n",
      "\n",
      "\n",
      "@transform(third_task, suffix(\".output1\"), \".output2\")\n",
      "def fourth_task(input_file, output_file):\n",
      "    # make output file\n",
      "    open(output_file, \"w\")\n",
      "\n",
      "pipeline_run([fourth_task], verbose = 1, multiprocess = 5)\n",
      "#pipeline_printout(sys.stdout, [fourth_task], verbose = 5)\n",
      "pipeline_printout_graph(\"flowchart-test.svg\", \"svg\", [fourth_task])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    Job completed\n",
        "Completed Task = first_task\n",
        "    Job completed\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Completed Task = second_task\n",
        "    Job  = [job1.input -> job1.output1, some_extra.example, 14] completed\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    Job  = [job2.input -> job2.output1, some_extra.example, 14] completed\n",
        "    Job  = [job3.input -> job3.output1, some_extra.example, 14] completed\n",
        "Completed Task = third_task\n",
        "    Job  = [job1.output1 -> job1.output2] completed\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    Job  = [job2.output1 -> job2.output2] completed\n",
        "    Job  = [job3.output1 -> job3.output2] completed\n",
        "Completed Task = fourth_task\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!rm -r -f flowchart-test.png"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ls"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "First-notebook.ipynb                job1.output1  job2.output2  \u001b[0m\u001b[01;34mreport\u001b[0m/\r\n",
        "Ruffus-and-pipeline-building.ipynb  job1.output2  job3.input    \u001b[01;34msrc\u001b[0m/\r\n",
        "\u001b[01;35mflowchart-test.svg\u001b[0m                  job2.input    job3.output1  test.ipynb\r\n",
        "job1.input                          job2.output1  job3.output2  test.py\r\n",
        "\u001b[m"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# to run a .py file with several featrues (like debugging, time measured, etc.). run? for more.\n",
      "\n",
      "#%run -t -d -p test.py\n",
      "\n",
      "#%run -t -d -b343 /ifs/devel/antoniob/src/projects/ChIP-Exo/src/pipeline_exo.py\n",
      "\n",
      "run?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!eog flowchart-test.svg"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!mkdir Ruffus-tests.dir"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "mkdir: cannot create directory `Ruffus-tests.dir': File exists\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/ifs/devel/antoniob/src/projects/ChIP-Exo/Ruffus-tests.dir\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "First-notebook.ipynb\t\t    Ruffus-tests.dir  src\t  test.py\r\n",
        "Ruffus-and-pipeline-building.ipynb  report\t      test.ipynb\r\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd Ruffus-tests.dir/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/ifs/devel/antoniob/src/projects/ChIP-Exo/Ruffus-tests.dir\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ls"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.chunks   2.chunks  4.chunks  6.chunks  8.chunks  random_numbers.list\r\n",
        "1.sums     2.sums    4.sums    6.sums    8.sums    sentinel_flag\r\n",
        "10.chunks  3.chunks  5.chunks  7.chunks  9.chunks  variance.result\r\n",
        "10.sums    3.sums    5.sums    7.sums    9.sums\r\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "NUMBER_OF_RANDOMS = 10000\n",
      "CHUNK_SIZE = 1000\n",
      "\n",
      "\n",
      "from ruffus import *\n",
      "import time, random, glob, os\n",
      "\n",
      "#@follows(mkdir(\"Ruffus-tests.dir\"))\n",
      "#def change_directory(directory_name):\n",
      "#    a = !cd $directory_name\n",
      "#    return a\n",
      "\n",
      "#---------------------------------------------------------------\n",
      "#\n",
      "#   Create random numbers\n",
      "#\n",
      "\n",
      "#@follows(change_directory(\"Ruffus-tests.dir\"))\n",
      "@files(None, \"random_numbers.list\")\n",
      "def create_random_numbers(input_file_name, output_file_name):\n",
      "    f = open(output_file_name, \"w\")\n",
      "    for i in range(NUMBER_OF_RANDOMS):\n",
      "        f.write(\"%g\\n\" % (random.random() * 100.0))\n",
      "\n",
      "#---------------------------------------------------------------\n",
      "#\n",
      "#   Split initial file\n",
      "#\n",
      "@follows(create_random_numbers)\n",
      "@split(\"random_numbers.list\", \"*.chunks\")\n",
      "def step_5_split_numbers_into_chunks (input_file_name, output_files):\n",
      "    \"\"\"\n",
      "        Splits random numbers file into XXX files of CHUNK_SIZE each\n",
      "    \"\"\"\n",
      "    #\n",
      "    #   clean up files from previous runs\n",
      "    #\n",
      "    for f in glob.glob(\"*.chunks\"):\n",
      "        os.unlink(f)\n",
      "    #\n",
      "    #   create new file every CHUNK_SIZE lines and\n",
      "    #       copy each line into current file\n",
      "    #\n",
      "    output_file = None\n",
      "    cnt_files = 0\n",
      "    for i, line in enumerate(open(input_file_name)):\n",
      "        if i % CHUNK_SIZE == 0:\n",
      "            cnt_files += 1\n",
      "            output_file = open(\"%d.chunks\" % cnt_files, \"w\")\n",
      "        output_file.write(line)\n",
      "\n",
      "#pipeline_run([step_5_split_numbers_into_chunks], verbose = 2)\n",
      "\n",
      "#---------------------------------------------------------------\n",
      "#\n",
      "#   Calculate sum and sum of squares for each chunk file\n",
      "#\n",
      "@transform(step_5_split_numbers_into_chunks, suffix(\".chunks\"), \".sums\")\n",
      "def step_6_calculate_sum_of_squares (input_file_name, output_file_name):\n",
      "    output = open(output_file_name,  \"w\")\n",
      "    sum_squared, sum = [0.0, 0.0]\n",
      "    cnt_values = 0\n",
      "    for line in open(input_file_name):\n",
      "        cnt_values += 1\n",
      "        val = float(line.rstrip())\n",
      "        sum_squared += val * val\n",
      "        sum += val\n",
      "    output.write(\"%s\\n%s\\n%d\\n\" % (repr(sum_squared), repr(sum), cnt_values))\n",
      "\n",
      "#pipeline_run([step_6_calculate_sum_of_squares], verbose = 1)\n",
      "\n",
      "#---------------------------------------------------------------\n",
      "#\n",
      "#   Calculate sum and sum of squares for each chunk\n",
      "#\n",
      "\n",
      "@posttask(lambda: sys.stdout.write(\"hooray\\n\"))\n",
      "@posttask(touch_file(\"sentinel_flag\"))\n",
      "@merge(step_6_calculate_sum_of_squares, \"variance.result\")\n",
      "def step_7_calculate_variance (input_file_names, output_file_name):\n",
      "    \"\"\"\n",
      "    Calculate variance naively\n",
      "    \"\"\"\n",
      "    output = open(output_file_name,  \"w\")\n",
      "    #\n",
      "    #   initialise variables\n",
      "    #\n",
      "    all_sum_squared = 0.0\n",
      "    all_sum         = 0.0\n",
      "    all_cnt_values  = 0.0\n",
      "    #\n",
      "    # added up all the sum_squared, and sum and cnt_values from all the chunks\n",
      "    #\n",
      "    for input_file_name in input_file_names:\n",
      "        sum_squared, sum, cnt_values = map(float, open(input_file_name).readlines())\n",
      "        all_sum_squared += sum_squared\n",
      "        all_sum         += sum\n",
      "        all_cnt_values  += cnt_values\n",
      "    all_mean = all_sum / all_cnt_values\n",
      "    variance = (all_sum_squared - all_sum * all_mean)/(all_cnt_values)\n",
      "    #\n",
      "    #   print output\n",
      "    #\n",
      "    print >>output, variance\n",
      "\n",
      "#---------------------------------------------------------------\n",
      "#\n",
      "#       Run\n",
      "#\n",
      "pipeline_run([step_7_calculate_variance], [create_random_numbers], verbose = 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    Job  = [None -> random_numbers.list] completed\n",
        "Completed Task = create_random_numbers\n",
        "    Job  = [random_numbers.list -> *.chunks] completed\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Completed Task = step_5_split_numbers_into_chunks\n",
        "    Job  = [1.chunks -> 1.sums] completed\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "    Job  = [10.chunks -> 10.sums] completed\n",
        "    Job  = [2.chunks -> 2.sums] completed\n",
        "    Job  = [3.chunks -> 3.sums] completed\n",
        "    Job  = [4.chunks -> 4.sums] completed\n",
        "    Job  = [5.chunks -> 5.sums] completed\n",
        "    Job  = [6.chunks -> 6.sums] completed\n",
        "    Job  = [7.chunks -> 7.sums] completed\n",
        "    Job  = [8.chunks -> 8.sums] completed\n",
        "    Job  = [9.chunks -> 9.sums] completed\n",
        "Completed Task = step_6_calculate_sum_of_squares\n",
        "    Job  = [[1.sums, 10.sums, 2.sums, 3.sums, 4.sums, 5.sums, 6.sums, 7.sums, 8.sums, 9.sums] -> variance.result] completed\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "hooray\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Completed Task = step_7_calculate_variance\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ll"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "total 779\r\n",
        "-rw-rw-r-- 1 antoniob  7912 Apr 16 13:33 1.chunks\r\n",
        "-rw-rw-r-- 1 antoniob    43 Apr 16 13:33 1.sums\r\n",
        "-rw-rw-r-- 1 antoniob  7909 Apr 16 13:33 10.chunks\r\n",
        "-rw-rw-r-- 1 antoniob    42 Apr 16 13:33 10.sums\r\n",
        "-rw-rw-r-- 1 antoniob  7913 Apr 16 13:33 2.chunks\r\n",
        "-rw-rw-r-- 1 antoniob    42 Apr 16 13:33 2.sums\r\n",
        "-rw-rw-r-- 1 antoniob  7889 Apr 16 13:33 3.chunks\r\n",
        "-rw-rw-r-- 1 antoniob    42 Apr 16 13:33 3.sums\r\n",
        "-rw-rw-r-- 1 antoniob  7894 Apr 16 13:33 4.chunks\r\n",
        "-rw-rw-r-- 1 antoniob    42 Apr 16 13:33 4.sums\r\n",
        "-rw-rw-r-- 1 antoniob  7901 Apr 16 13:33 5.chunks\r\n",
        "-rw-rw-r-- 1 antoniob    42 Apr 16 13:33 5.sums\r\n",
        "-rw-rw-r-- 1 antoniob  7908 Apr 16 13:33 6.chunks\r\n",
        "-rw-rw-r-- 1 antoniob    42 Apr 16 13:33 6.sums\r\n",
        "-rw-rw-r-- 1 antoniob  7912 Apr 16 13:33 7.chunks\r\n",
        "-rw-rw-r-- 1 antoniob    41 Apr 16 13:33 7.sums\r\n",
        "-rw-rw-r-- 1 antoniob  7910 Apr 16 13:33 8.chunks\r\n",
        "-rw-rw-r-- 1 antoniob    43 Apr 16 13:33 8.sums\r\n",
        "-rw-rw-r-- 1 antoniob  7894 Apr 16 13:33 9.chunks\r\n",
        "-rw-rw-r-- 1 antoniob    43 Apr 16 13:33 9.sums\r\n",
        "-rw-rw-r-- 1 antoniob 79042 Apr 16 13:33 random_numbers.list\r\n",
        "-rw-rw-r-- 1 antoniob     0 Apr 16 13:33 sentinel_flag\r\n",
        "-rw-rw-r-- 1 antoniob    14 Apr 16 13:33 variance.result\r\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "remove_chunks = !rm -r -f *chunks\n",
      "remove_sums = !rm -r -f *sums\n",
      "remove_job = !rm -r -f job*\n",
      "!rm -r -f flowchart-test.svg\n",
      "!rm -r -f random_numbers.list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def change_directory(directory_name):\n",
      "    a = !cd $directory_name\n",
      "    return a\n",
      "\n",
      "change_directory('Ruffus-tests.dir')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ls"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "First-notebook.ipynb                \u001b[0m\u001b[01;34mRuffus-tests.dir\u001b[0m/  \u001b[01;34msrc\u001b[0m/\r\n",
        "Ruffus-and-pipeline-building.ipynb  \u001b[01;34mreport\u001b[0m/\r\n",
        "\u001b[m"
       ]
      }
     ],
     "prompt_number": 11
    }
   ],
   "metadata": {}
  }
 ]
}